好的，模拟逾渗系统通常涉及以下几个关键步骤，这里以最常见的**二维方格点阵上的点逾渗 (Site Percolation on a 2D Square Lattice)** 为例进行说明：

**目标：** 通过计算机模拟来确定逾渗阈值 $p_c$，并观察临界状态下团簇的分形特征。

**模拟步骤：**

1.  **创建格点 (Lattice Setup):**
    *   定义一个二维数组（例如，使用 Python 的 NumPy 库创建一个 `L x L` 的数组），代表方格点阵。
    *   初始化所有格点为“空”状态（例如，用 0 表示）。
    *   `L` 是格点的边长，选择一个合适的尺寸，例如 `L=50` 或 `L=100`。更大的 `L` 结果更精确，但计算量也更大。

2.  **随机占据格点 (Random Occupation):**
    *   选择一个占据概率 `p` (0 到 1 之间)。这是我们要研究的参数。
    *   遍历格点中的每一个位置 `(i, j)`。
    *   为每个位置生成一个 [0, 1) 区间内的随机数 `r`。
    *   如果 `r < p`，则将该格点标记为“占据”状态（例如，将数组对应元素值设为 1）。否则，保持为“空”（0）。
    *   完成这一步后，你就得到了一个特定概率 `p` 下的随机格点构型。

3.  **识别团簇 (Cluster Identification):**
    *   这是核心步骤。你需要找到所有相互连接的“占据”格点组成的团簇。两个占据的格点如果相邻（上下左右，有时也包括对角线，取决于定义）则认为它们属于同一个团簇。
    *   **常用算法：**
        *   **深度优先搜索 (DFS) 或 广度优先搜索 (BFS):**
            *   创建一个同样大小的“访问标记”数组，初始都为“未访问”。
            *   遍历格点。如果遇到一个“占据”且“未访问”的格点：
                *   将其标记为“已访问”。
                *   启动一个 DFS 或 BFS，从该点出发，找到所有与之相连通的“占据”格点。
                *   将找到的所有这些格点都标记为属于同一个新发现的团簇（可以给它们分配一个唯一的团簇 ID）。
                *   标记这些点为“已访问”。
            *   重复此过程，直到所有“占据”格点都被访问并分配了团簇 ID。
        *   **Hoshen-Kopelman 算法:** 一种更高效的扫描线算法，特别适合处理大格点。它逐行扫描格点，根据邻居的标签给当前格点分配标签，并处理标签合并（当一个点连接了两个之前认为是不同团簇的点时）。通常需要使用“并查集 (Union-Find)”数据结构来高效管理标签等价关系。
    *   **输出：** 最终得到一个 `L x L` 的数组，其中每个元素的值代表该格点所属的团簇 ID（如果是空点则为 0 或其他特殊值）。

4.  **检查是否逾渗 (Check for Spanning):**
    *   确定是否存在一个“贯穿团簇”，即连接系统相对边界的团簇。
    *   对于一个 `L x L` 的格点，通常检查：是否存在一个团簇，其成员同时出现在最顶行 (y=0) 和最底行 (y=L-1)？（或者最左列 x=0 和最右列 x=L-1）。
    *   遍历顶行（或左列）的所有格点，记录下它们所属的团簇 ID（非 0 的）。
    *   然后遍历底行（或右列），检查是否有任何格点的团簇 ID 出现在之前顶行记录的 ID 集合中。
    *   如果存在匹配的 ID，则认为该构型**逾渗**了。

5.  **确定逾渗阈值 $p_c$:**
    *   $p_c$ 是一个统计平均值，不能通过单次模拟确定。
    *   **方法：**
        *   选择一系列概率 `p` 值（例如，在预期 $p_c$ 附近，对于 2D 方格点逾渗 $p_c \approx 0.5927$，可以选择 `p` 从 0.5 到 0.7，步长 0.01）。
        *   对于**每一个** `p` 值：
            *   重复执行步骤 1-4 **很多次**（例如 `N_runs = 100` 或 1000 次），每次使用不同的随机数种子生成不同的构型。
            *   计算**逾渗概率 $\Pi(p, L)$**：在这 `N_runs` 次模拟中，出现逾渗构型的**比例**。
        *   绘制 $\Pi(p, L)$ 关于 `p` 的曲线。你会看到一个 S 形曲线，在 $p_c$ 附近急剧从 0 上升到 1。
        *   通常定义 $p_c(L)$ 为 $\Pi(p_c(L), L) = 0.5$ 时的概率值（可以通过插值找到）。
        *   **有限尺寸标度分析 (Optional but important):** 为了得到更精确的 $p_c$（对应无限大格点），需要对不同尺寸 `L` 计算出的 $p_c(L)$ 进行外插，利用标度理论 $p_c(L) - p_c \sim L^{-1/\nu}$（其中 $\nu$ 是关联长度临界指数）。

6.  **分析临界团簇的分形特征 (在 $p \approx p_c$ 时):**
    *   将概率 `p` 设置为你估计的 $p_c(L)$ 值。
    *   运行一次模拟 (步骤 1-3)。
    *   找到最大的团簇（包含最多格点的团簇）。如果系统恰好逾渗，这个通常就是逾渗团簇。
    *   **可视化：** 将最大团簇中的格点绘制出来（例如，用 Matplotlib 的 `imshow` 或 `scatter`）。你会直观地看到其复杂、自相似的结构。
    *   **计算分形维数 (Box Counting):**
        *   获取最大团簇所有格点的坐标。
        *   选择一系列盒子边长 $\epsilon$ (例如 $\epsilon = L, L/2, L/4, ..., 1$)。
        *   对于每个 $\epsilon$，用边长为 $\epsilon$ 的正方形网格覆盖包含该团簇的区域。
        *   计算有多少个盒子 $N(\epsilon)$ 至少包含团簇中的一个点。
        *   绘制 $\log(N(\epsilon))$ 对 $\log(1/\epsilon)$ 的图。
        *   如果数据点在一定范围内呈线性关系，其斜率的绝对值就是该团簇的盒子计数维数 $D_f$。

**实现要点：**

*   **编程语言：** Python (配合 NumPy, Matplotlib, SciPy) 是非常常用的选择。
*   **数据结构：** NumPy 数组对于格点操作非常高效。
*   **随机数：** 使用可靠的伪随机数生成器。
*   **效率：** 团簇识别是计算瓶颈，选择或实现高效的算法很重要。

通过这些步骤，你就可以用计算物理的方法来模拟逾渗现象，定量地研究其临界行为和分形几何特性了。

Okay, here's a Python code example using `numpy`, `scipy`, and `matplotlib` to simulate site percolation on a 2D square lattice. This code will:

1.  Generate random lattices for different occupation probabilities `p`.
2.  Identify clusters using `scipy.ndimage.label`.
3.  Calculate the spanning probability as a function of `p`.
4.  Visualize a critical cluster (near the estimated \(p_c\)).
5.  Perform box counting on the largest cluster at \(p \approx p_c\) to estimate its fractal dimension.

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy.ndimage import label
import time # To time the simulation

# --- Simulation Parameters ---
L = 100  # Lattice size (L x L)
N_runs = 50 # Number of simulations per probability p for spanning probability
# Probabilities to test for spanning curve (centered around expected pc ~ 0.5927)
p_values_spanning = np.linspace(0.5, 0.7, 41)
p_critical_estimate = 0.5927 # Use this for visualizing the critical cluster

# --- Helper Functions ---

def create_lattice(L, p):
    """Creates an LxL lattice with sites occupied with probability p."""
    lattice = np.random.rand(L, L) < p
    return lattice.astype(int) # Convert boolean to int (1=occupied, 0=empty)

def find_clusters(lattice):
    """
    Finds connected clusters in the lattice.
    Uses 4-connectivity (von Neumann neighborhood).
    Returns the labeled lattice and the number of clusters found (excluding background).
    """
    # structure defines connectivity: [[0,1,0],[1,1,1],[0,1,0]] for 4-connectivity
    structure = np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]], dtype=bool)
    labeled_lattice, num_labels = label(lattice, structure=structure)
    return labeled_lattice, num_labels

def check_spanning(labeled_lattice, L):
    """Checks if any cluster spans from top row (y=0) to bottom row (y=L-1)."""
    top_labels = np.unique(labeled_lattice[0, :])
    bottom_labels = np.unique(labeled_lattice[L-1, :])
    # Find common labels (ignoring background label 0)
    common_labels = np.intersect1d(top_labels[top_labels > 0], bottom_labels[bottom_labels > 0])
    return len(common_labels) > 0

def get_largest_cluster_points(labeled_lattice):
    """Finds the coordinates of points belonging to the largest cluster."""
    unique_labels, counts = np.unique(labeled_lattice, return_counts=True)
    # Ignore background label 0
    if len(unique_labels) <= 1: # Only background or no clusters
        return np.array([])
    
    # Find the label with the maximum count (excluding background count at index 0)
    largest_cluster_label_index = np.argmax(counts[1:]) + 1 # +1 because we sliced off the first element
    largest_cluster_label = unique_labels[largest_cluster_label_index]

    # Get coordinates where the lattice has this label
    points = np.argwhere(labeled_lattice == largest_cluster_label)
    # points is an Nx2 array where each row is [row_index, col_index]
    return points

def box_counting(points, L, min_box_size=1, max_box_size=None):
    """
    Performs box counting on a set of points within an LxL grid.
    Args:
        points (np.array): Nx2 array of [row, col] coordinates.
        L (int): The size of the grid the points live in.
        min_box_size (int): Smallest box size (epsilon) to use.
        max_box_size (int): Largest box size (epsilon) to use. Defaults to L.
    Returns:
        box_sizes (np.array): Array of box sizes (epsilon) used.
        box_counts (np.array): Array of corresponding box counts N(epsilon).
    """
    if points.size == 0:
        return np.array([]), np.array([])
        
    if max_box_size is None:
        max_box_size = L

    # Generate box sizes (powers of 2 are common, but linear steps on log scale work too)
    n_scales = int(np.log2(max_box_size / min_box_size)) + 1
    box_sizes = np.logspace(np.log2(min_box_size), np.log2(max_box_size), num=n_scales, base=2.0)
    box_sizes = np.unique(np.round(box_sizes).astype(int)) # Ensure integer sizes and unique
    box_sizes = box_sizes[box_sizes >= min_box_size] # Ensure min size respected

    box_counts = []
    actual_box_sizes = [] # Store sizes actually used

    for epsilon in box_sizes:
        if epsilon == 0: continue # Skip invalid box size

        # Use a set to efficiently store occupied box indices
        occupied_boxes = set()
        for r, c in points:
            box_r = int(r // epsilon)
            box_c = int(c // epsilon)
            occupied_boxes.add((box_r, box_c))

        if len(occupied_boxes) > 0:
            box_counts.append(len(occupied_boxes))
            actual_box_sizes.append(epsilon)

    return np.array(actual_box_sizes), np.array(box_counts)

# --- Main Simulation ---

if __name__ == "__main__":
    start_time = time.time()

    # 1. Calculate Spanning Probability
    print(f"Calculating spanning probability for L={L}...")
    spanning_probs = []
    for p in p_values_spanning:
        spanning_count = 0
        for run in range(N_runs):
            lattice = create_lattice(L, p)
            labeled_lattice, _ = find_clusters(lattice)
            if check_spanning(labeled_lattice, L):
                spanning_count += 1
        spanning_probs.append(spanning_count / N_runs)
        print(f"  p = {p:.4f}, Spanning Prob = {spanning_probs[-1]:.3f}")

    spanning_probs = np.array(spanning_probs)

    # Estimate pc as where probability is closest to 0.5
    pc_estimated_idx = np.argmin(np.abs(spanning_probs - 0.5))
    pc_estimated = p_values_spanning[pc_estimated_idx]
    print(f"\nEstimated Percolation Threshold pc(L={L}) ≈ {pc_estimated:.4f}")

    # 2. Generate and Visualize a Critical Cluster
    print(f"\nGenerating a lattice near critical point p={p_critical_estimate}...")
    critical_lattice = create_lattice(L, p_critical_estimate)
    labeled_critical, num_labels = find_clusters(critical_lattice)
    print(f"Found {num_labels} clusters.")

    # Find the largest cluster
    largest_cluster_pts = get_largest_cluster_points(labeled_critical)
    print(f"Largest cluster size: {len(largest_cluster_pts)} points.")

    # Create an array showing only the largest cluster
    largest_cluster_viz = np.zeros((L, L), dtype=int)
    if largest_cluster_pts.size > 0:
        # Need to transpose points from [row, col] to tuple for indexing
        rows, cols = largest_cluster_pts.T
        largest_cluster_viz[rows, cols] = 1

    # 3. Perform Box Counting on the Largest Cluster
    print("\nPerforming Box Counting on the largest cluster...")
    box_sizes, box_counts = box_counting(largest_cluster_pts, L)

    # Filter out potential issues for log-log plot (e.g., count=0 or size=0)
    valid_indices = (box_counts > 0) & (box_sizes > 0)
    box_sizes_valid = box_sizes[valid_indices]
    box_counts_valid = box_counts[valid_indices]

    fractal_dimension = 0.0
    if len(box_sizes_valid) > 1:
        # Calculate log values
        log_epsilon = np.log(1.0 / box_sizes_valid) # Use 1/epsilon for positive slope
        log_N = np.log(box_counts_valid)

        # Fit a line (degree 1 polynomial) to the log-log data
        # We fit log(N) = D * log(1/epsilon) + C
        coeffs = np.polyfit(log_epsilon, log_N, 1)
        fractal_dimension = coeffs[0] # The slope is the fractal dimension D_f
        print(f"\nEstimated Fractal Dimension (Box Counting) D_f ≈ {fractal_dimension:.3f}")
    else:
        print("\nNot enough data points for fractal dimension calculation.")


    end_time = time.time()
    print(f"\nTotal simulation time: {end_time - start_time:.2f} seconds")

    # --- Plotting ---
    plt.figure(figsize=(18, 6))

    # Plot 1: Spanning Probability Curve
    plt.subplot(1, 3, 1)
    plt.plot(p_values_spanning, spanning_probs, 'bo-', label=f'L={L}, N_runs={N_runs}')
    plt.axvline(pc_estimated, color='r', linestyle='--', label=f'Est. $p_c \\approx {pc_estimated:.4f}$')
    plt.axhline(0.5, color='grey', linestyle=':', label='Prob = 0.5')
    plt.xlabel("Occupation Probability (p)")
    plt.ylabel("Spanning Probability $\\Pi(p, L)$")
    plt.title("Percolation Spanning Probability")
    plt.legend()
    plt.grid(True)

    # Plot 2: Visualization of the Largest Critical Cluster
    plt.subplot(1, 3, 2)
    plt.imshow(largest_cluster_viz, cmap='binary', origin='lower', interpolation='nearest')
    plt.title(f"Largest Cluster at p={p_critical_estimate:.4f} (L={L})")
    plt.xlabel("x")
    plt.ylabel("y")
    # Remove ticks for cleaner look
    plt.xticks([])
    plt.yticks([])


    # Plot 3: Log-Log Plot for Fractal Dimension
    plt.subplot(1, 3, 3)
    if len(box_sizes_valid) > 1:
        plt.plot(log_epsilon, log_N, 'gs-', label='Data points')
        # Plot the fitted line
        plt.plot(log_epsilon, np.polyval(coeffs, log_epsilon), 'r--', label=f'Fit: $D_f \\approx {fractal_dimension:.3f}$')
        plt.xlabel("$\\log(1 / \\epsilon)$")
        plt.ylabel("$\\log(N(\\epsilon))$")
        plt.title("Box Counting Log-Log Plot")
        plt.legend()
        plt.grid(True)
    else:
        plt.text(0.5, 0.5, "Not enough data for plot", ha='center', va='center')
        plt.title("Box Counting Log-Log Plot")


    plt.tight_layout()
    plt.show()
```

**How to Run:**

1.  Make sure you have `numpy`, `scipy`, and `matplotlib` installed (`pip install numpy scipy matplotlib`).
2.  Save the code as a Python file (e.g., `percolation_sim.py`).
3.  Run it from your terminal: `python percolation_sim.py`

**Explanation:**

1.  **Parameters:** Set `L`, `N_runs`, `p_values_spanning`, and `p_critical_estimate`. Larger `L` and `N_runs` give better results but take longer.
2.  **`create_lattice`:** Simple NumPy function to generate the random grid.
3.  **`find_clusters`:** Uses `scipy.ndimage.label` which is very efficient for finding connected components. The `structure` argument defines 4-connectivity (neighbors are up, down, left, right).
4.  **`check_spanning`:** Finds unique cluster labels on the top and bottom rows and checks if there's any overlap (excluding the background label 0).
5.  **Spanning Probability Loop:** Iterates through `p_values_spanning`, runs `N_runs` simulations for each `p`, counts how many resulted in a spanning cluster, and calculates the probability.
6.  **`get_largest_cluster_points`:** Finds the label corresponding to the cluster with the most points (excluding background) and returns the coordinates of those points.
7.  **`box_counting`:** Implements the box-counting algorithm. It iterates through different box sizes (`epsilon`), determines which boxes contain points from the input `points` set, and counts these occupied boxes (`N(epsilon)`).
8.  **Main Block:** Orchestrates the simulation, calls the functions, performs the linear fit on the log-log data from box counting to find the slope (fractal dimension), and generates the plots.

This code provides a solid foundation for exploring percolation phenomena computationally. You can experiment with different `L` values, connectivity rules (e.g., 8-connectivity by changing the `structure` in `find_clusters`), or adapt it for bond percolation.